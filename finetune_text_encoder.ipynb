{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Specify the path to your TSV file\n",
    "train_tsv_file_path = '/home/allenfu/cyc/23Fall-269/Train_GCC-training.tsv'\n",
    "val_tsv_file_path = '/home/allenfu/cyc/23Fall-269/Validation_GCC-1.1.0-Validation.tsv'\n",
    "\n",
    "# Read the TSV file into a DataFrame\n",
    "train_df = pd.read_csv(train_tsv_file_path, delimiter='\\t', header=None)[0]\n",
    "val_df = pd.read_csv(val_tsv_file_path, delimiter='\\t', header=None)[0]\n",
    "\n",
    "def remove_spaces(sentence):\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(f' {punctuation}', punctuation)\n",
    "    return ' '.join(sentence.split())\n",
    "\n",
    "train_df = train_df.apply(remove_spaces)\n",
    "val_df = val_df.apply(remove_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allenfu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, processor, max_length=64):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source_sentence = self.data.iloc[idx]\n",
    "        \n",
    "        # Tokenize and encode the source sentence\n",
    "        t5_tokens = self.tokenizer.encode_plus(\n",
    "            source_sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        t5_inputs =  {\n",
    "            'input_ids': t5_tokens['input_ids'].squeeze(),\n",
    "            'attention_mask': t5_tokens['attention_mask'].squeeze(),\n",
    "            'target_ids': t5_tokens['input_ids'].squeeze(),  # Target is the same as the input\n",
    "            'target_mask': t5_tokens['attention_mask'].squeeze(),\n",
    "            'target': source_sentence\n",
    "        }\n",
    "\n",
    "        clip_tokens = self.processor(\n",
    "            text=source_sentence, \n",
    "            images=torch.zeros((3, 224, 224)), \n",
    "            return_tensors=\"pt\", \n",
    "            padding='max_length', \n",
    "            max_length=self.max_length, \n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        clip_inputs = {\n",
    "            'input_ids': clip_tokens['input_ids'].squeeze(),\n",
    "            'attention_mask': clip_tokens['attention_mask'].squeeze(),\n",
    "            'pixel_values': clip_tokens[\"pixel_values\"].view(3, 224, 224),\n",
    "            'target_ids': clip_tokens['input_ids'].squeeze(),  # Target is the same as the input\n",
    "            'target_mask': clip_tokens['attention_mask'].squeeze(),\n",
    "            'target': source_sentence\n",
    "        }\n",
    "\n",
    "        return clip_inputs, t5_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, CLIPModel, CLIPProcessor\n",
    "from tqdm import tqdm\n",
    "        \n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, bottleneck_dim=4096):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            # nn.Linear(input_dim, bottleneck_dim),\n",
    "            # nn.LayerNorm(bottleneck_dim),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(bottleneck_dim, output_dim),\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.LayerNorm(output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # self.layer = nn.Linear(input_dim, output_dim)\n",
    "        # self.norm = nn.LayerNorm(output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.blocks(x)\n",
    "\n",
    "class CLIPEval(nn.Module):\n",
    "    def __init__(self, t5_model_path, device='cuda'):\n",
    "        super(CLIPEval, self).__init__()\n",
    "        self.encoder = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        self.encoder.load_state_dict(torch.load('/home/allenfu/269/clip.pt'))\n",
    "        self.bottleneck = Bottleneck(512, 768)\n",
    "        self.decoder = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "        self.decoder.load_state_dict(torch.load(t5_model_path))\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "        self.device = device\n",
    "\n",
    "        # Set requires_grad to False for encoder and decoder parameters\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.decoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Set requires_grad to True for dimension transform layer parameters\n",
    "        for param in self.bottleneck.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, clip_inputs, t5_inputs, train=True):\n",
    "        if train:\n",
    "            # inputs_embeds = self.encoder.text_model.embeddings.token_embedding(clip_inputs['input_ids'].to(self.device))\n",
    "            # t5_inputs_embeds = self.bottleneck(inputs_embeds)\n",
    "            # t5_inputs_embeds = self.decoder.get_input_embeddings()(t5_inputs[\"input_ids\"].to(self.device))[:, 0, :]\n",
    "            encoder_outputs = self.encoder.text_model(\n",
    "                input_ids=clip_inputs[\"input_ids\"].to(self.device), \n",
    "                attention_mask=clip_inputs[\"attention_mask\"].to(self.device),\n",
    "                # output_attentions=True,\n",
    "                # output_hidden_states=True,\n",
    "            )\n",
    "            encoder_outputs['last_hidden_state'] = self.bottleneck(encoder_outputs['last_hidden_state'])\n",
    "            output = self.decoder(\n",
    "                # inputs_embeds=t5_inputs_embeds,\n",
    "                encoder_outputs=encoder_outputs,\n",
    "                # input_ids=t5_inputs['input_ids'].to(self.device),\n",
    "                attention_mask=t5_inputs['attention_mask'].to(self.device),\n",
    "                # decoder_input_ids=torch.tensor([[self.tokenizer.pad_token_id]] * t5_inputs_embeds.shape[0]),\n",
    "                labels=t5_inputs['target_ids'].to(self.device)\n",
    "            )\n",
    "            return output.loss\n",
    "        else:\n",
    "            # inputs_embeds = self.encoder.text_model.embeddings.token_embedding(clip_inputs['input_ids'].to(self.device))\n",
    "            # t5_inputs_embeds = self.bottleneck(inputs_embeds)\n",
    "            # t5_inputs_embeds = self.decoder.get_input_embeddings()(t5_inputs[\"input_ids\"].to(self.device))[:, 0, :]\n",
    "            encoder_outputs = self.encoder.text_model(\n",
    "                input_ids=clip_inputs[\"input_ids\"].to(self.device), \n",
    "                attention_mask=clip_inputs[\"attention_mask\"].to(self.device),\n",
    "                # output_attentions=True,\n",
    "                # output_hidden_states=True,\n",
    "            )\n",
    "            encoder_outputs['last_hidden_state'] = self.bottleneck(encoder_outputs['last_hidden_state'])\n",
    "            output = self.decoder.generate(\n",
    "                # inputs_embeds=t5_inputs_embeds,\n",
    "                encoder_outputs=encoder_outputs,\n",
    "                attention_mask=t5_inputs['attention_mask'].to(self.device),\n",
    "                decoder_input_ids=torch.tensor([[self.tokenizer.pad_token_id]] * t5_inputs['input_ids'].shape[0]).to(self.device)\n",
    "            )\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 25925/25925 [1:24:59<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Loss: 0.17930788880316478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 1: 100%|██████████| 124/124 [00:59<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation EM Score: 0.35795454545454547\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  25%|██▍       | 6392/25925 [20:56<1:04:00,  5.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     33\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 35\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     37\u001b[0m average_loss \u001b[39m=\u001b[39m total_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_dataloader)\n\u001b[1;32m     38\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m, Average Loss: \u001b[39m\u001b[39m{\u001b[39;00maverage_loss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "# Load the T5 tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Create the dataset and DataLoader\n",
    "train_dataset = Seq2SeqDataset(train_df, tokenizer, processor)\n",
    "val_dataset = Seq2SeqDataset(val_df, tokenizer, processor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Initialize the autoencoder model\n",
    "t5_model_path = '/home/allenfu/cyc/23Fall-269/t5_model.pth'\n",
    "clip_model = CLIPEval(t5_model_path, device).to(device)\n",
    "clip_model.load_state_dict(torch.load('clip_model.pth'))\n",
    "\n",
    "# Define the optimizer and learning rate scheduler\n",
    "optimizer = optim.AdamW(clip_model.bottleneck.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "best_em_score = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    clip_model.train()\n",
    "\n",
    "    for clip_inputs, t5_inputs in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        loss = clip_model(clip_inputs, t5_inputs, train=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}')\n",
    "\n",
    "    # Optionally update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Evaluate with Exact Match (EM) on a validation set\n",
    "    clip_model.eval()\n",
    "    with torch.no_grad():\n",
    "        em_count = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for clip_inputs, t5_inputs in tqdm(val_dataloader, desc=f'Validation - Epoch {epoch + 1}'):\n",
    "            # Generate sequences\n",
    "            generated_ids = clip_model(clip_inputs, t5_inputs, train=False).detach().cpu().numpy()\n",
    "\n",
    "            # Decode token IDs to strings\n",
    "            generated_sentences = [tokenizer.decode(ids, skip_special_tokens=True) for ids in generated_ids]\n",
    "            target_sentences = t5_inputs['target']\n",
    "\n",
    "            # Check for exact match\n",
    "            em_count += sum(1 for gen, target in zip(generated_sentences, target_sentences) if gen == target)\n",
    "            total_samples += len(generated_sentences)\n",
    "\n",
    "        em_score = em_count / total_samples\n",
    "        print(f'Validation EM Score: {em_score}')\n",
    "\n",
    "        # Save the model if the EM score improves\n",
    "        if em_score > best_em_score:\n",
    "            best_em_score = em_score\n",
    "            torch.save(clip_model.state_dict(), 'clip_model.pth')\n",
    "            print(\"Model saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author of life, pictures in pictures ------- author: a life in photography-- in pictures\n",
      "leaves vector illustration on a seamless pattern ------- leaves vector illustration on a seamless pattern background\n",
      "a lot of dried fruit and nuts for sale in old quarters in city. ------- a lot of dried fruits and nuts for sale in old fashioned traditional grocery store in city on peninsula\n",
      "how to tell a girl how you feel ------- how to tell if a girl likes you\n",
      "today, today was another reminder of how person found the guy who invented the flip, the first ------- today this may look familiar, but person was the guy who discovered the first flip on a bicycle.\n",
      "is your child's school or a parade? strappy?? ------- is your child's school or nursery having a parade? stuck for inspiration? there are loads of great ideas over at profession, including this gorgeously scruffy spring meadow!\n",
      "cyclist shown in action during competitions in yellow ------- cyclist shown in action next to competitors wearing the yellow\n",
      "athlete goes out to the fans during the away side with an edge ------- athlete goes towards the fans in the away end after extending his side's lead\n",
      "a fox jumping on snow, and then hitting snail. ------- a fox jumping on the snow trying to catch mice.\n",
      "island written written on the sand with some stones ------- island written on the sand with assorted stones\n",
      "person displays the template for his helmet on the floor of his living room. ------- person displays the template for a helmet on the floor of his living room.\n",
      "young woman enjoying view on the terrace with mountains view ------- young woman enjoying view standing on the terrace with mountains view film format\n",
      "fashion shoot using balloons on a PR ------- fashion shoot, using balloons as a prop\n",
      "actor attends a special screening. ------- actor attends a special screening.\n",
      "young mother taking her baby for a walk in the countryside with a pram ------- young mother taking her baby for a walk in the countryside in a pram\n",
      "nilmarin is famous tourist attraction ------- nainital a famous tourist attraction\n",
      "portrait of a man teasing a woman ------- portrait of a man tempting a woman with donuts\n",
      "q: automotive industry business is launching a new range of hpa sedan ------- q by automotive industry business launching bhp flagship sedan later this year- report\n",
      "a close up shot of an avocado. ------- a closeup shot of a sliced avocado.\n",
      "cinematic style video video of young student in cafe. ------- cinematic style video of young student in cafe.\n",
      "inside finish off a door with only one of the other holes in the middle. ------- inside finish not good door was taller than all others.\n",
      "an entry from design and posters ------- an entry from design and posters\n",
      "engagement session in the snow ------- engagement session in the snow\n",
      "musician of hard rock artist performs onstage during music festival ------- musician of hard rock artist performs onstage during music festival\n",
      "a busy street corner in downtown ------- a busy street corner in downtown at dusk\n",
      "custom stuffed animals like a dog. ------- custom stuffed animals made to look like your dog.\n",
      "pop artist performs at show. ------- pop artist performs at show.\n",
      "person digs a zombie during an event ------- person drags a simulated victim to safety during an event\n",
      "a kettle of cow- pattern, illustration ------- a kettle of cow- print pattern, illustration\n",
      "white dress with a touch of yellow for the flower. ------- white dress with a touch of yellow for the flower girl.\n",
      "image of: design a simple bathroom ------- image of: design a simple bathroom\n",
      "donated toys will fill this truck! ------- donated toys will fill this truck.\n",
      "grilled pork loins on the baking tray ------- grilled pork ribs on the baking tray\n",
      "little girl looking through a cut out of green home ------- little girl looking through a cut out of a green home\n",
      "fast flowing water at the bottom of a water fall ------- fast flowing water at the bottom of a water fall\n",
      "froggy ears and a floppy dress. It's not that a ------- floppy ears and a fab dress, that's this hare with her handbag.\n",
      "airplane preparing for a take off with a member of the ground crew on the ground ------- airplane preparing for take off with a member of the ground crew in attendance.\n",
      "biological species on the fly ------- biological species on the fly\n",
      "person of artist performs on stage. ------- person of artist performs on stage.\n",
      "some of the participants at the meeting ------- some of the delegates at the meeting\n",
      "play around with different periods of period time to make your wedding look more like you want it. ------- play around with different period times to get the look that you want and fits your wedding theme.\n",
      "person with a lovely smile ------- person with a lovely smile\n",
      "testing out a cool design for me i think person ------- testing out a cool design i may paint for a friend of mine; person\n",
      "girl lying on the cliff above the seashore at sunset ------- girl lying on the cliff above seaside at sunset time\n",
      "long exposure exposure of a woman with umbrella on the beach ------- long exposure of a ghostly image of woman with umbrella on the beach\n",
      "visiting the headquarters of brand ------- visiting the birthplace of brand\n",
      "local children play football on the sandy beach, while a city watch the sunset ------- local children play football on the sandy beach at a city as tourists watch at dusk along administrative division\n",
      "pouring a cup of coffee ------- pouring a cup of coffee\n",
      "apartment converted to a modern living space for a young couple ------- apartment converted into a modern living space for a young couple\n",
      "a view of a tunnel while riding a train ------- a view of a tunnel while riding a train\n",
      "monks clean a garden in a temple. ------- monks clean a garden at a temple.\n",
      "image may contain: person, on stage, sitting, playing a musical instrument and indoor ------- image may contain: person, on stage, sitting, playing a musical instrument and indoor\n",
      "football player attends the press conference. ------- football player attends the press conference.\n",
      "image may contain: person, smiling, on stage and playing a musical instrument ------- image may contain: person, smiling, on stage and playing a musical instrument\n",
      "sweet little girl holding a bouquet of tulips in the yard ------- sweet little girl holding a bouquet of tulips in the yard\n",
      "a snowstorm hit country this weekend. ------- a snowstorm hit country and parts this past weekend.\n",
      "hedgehog on the keyboard of a laptop computer ------- hedgehog on the keyboard of a laptop computer\n",
      "image may contain: person, on stage, playing a musical instrument, sitting and night ------- image may contain: person, on stage, playing a musical instrument, sitting, night and indoor\n",
      "illustration of a wooden frame with square lines and french french lines ------- illustration of a wooden frame with square mat and french lines\n",
      "abstract colorful background with a man repairing a car. ------- abstract colorful background with a man silhouette repairing a car.\n",
      "we have a tiny kitchen to store in the living room. ------- we have a tiny kitchen so we need to store of our kitchenware in the living room.\n",
      "event is considered as the premier tournament. ------- event is considered the premier tournament on the competition.\n",
      "this is an example of a traditional water fountain landscape. ------- this is an example of a traditional water fountain landscape.\n",
      "new leaf grows grow in tree ------- new leaf is grown in tree\n",
      "market stall selling fresh bread ------- market stall selling fresh bread\n",
      "long waiting person with his children at train station. ------- long wait person with his children wait for a train at station.\n",
      "warning in place for more heavy snowfalls in country ------- severe warning in place as more heavy snow set to hit country\n",
      "road on the mountain during rainy season ------- road on the mountain during rainy season\n",
      "this beautiful calendar includes city and country in full color, complete with frame. ------- this beautiful calendar features city and country scenes in full color, suitable for framing.\n",
      "person draws a line in the pitch during the kick ------- person draws a line in vanishing spray on the pitch in preparation for a free kick\n",
      "even a small panel on your home can break up your monstrous appearance. ------- even a small amount of paneling around your home can break up a monotonous design and create an eye- catching accent.\n",
      "person, owner of the new chariot at old business. ------- person, owner at the new amphitheatre at oldest business.\n",
      "person and groom walking near the river. ------- person and groom walking near the river holding hands.\n",
      "female dancer in white dress dancing with green fabric on the summit. ------- female dancer in white dress dancing with green fabric in the wind on summit.\n",
      "waterfall at coast with cliffs in the background ------- waterfall at coast with cliffs in the background\n",
      "automotive industry business has launched a line of models ------- automotive industry business has launched a line of models\n",
      "a small bronze figure of author, child. ------- a small bronze figure of author as a child.\n",
      "images of people and action ------- images of people and action\n",
      "person closely watches his putt on the first hole of event. ------- person closely watches his putt on the first hole of event.\n",
      "aircraft line or helicopter flying from air over a mosque ------- aircraft line or helicopters of air force flying over a mosque\n",
      "wrapped present present with food on the table ------- wrapped present box with cuisine on the table\n",
      "pop artist in a suit ------- pop artist in a suit\n",
      "person: brings a good news, but has been able to breathe breathing ------- person: brings us good news as well when person has an operation to help her breathe\n",
      "tree lined apartments will be a living shade with a recumbent. ------- tree lined setting: the apartments will be in earthy tones with recessed balconies.\n",
      "aerial view of luxury yacht sailing near the coast ------- aerial view of luxury boat sailing close to the coast\n",
      "a set of industrial buildings on a white background illustration ------- a set of industrial buildings on a white background illustration\n",
      "head chef teaching his students how to whip cream in a commercial kitchen ------- head chef teaching his student how to whisk cream in a commercial kitchen\n",
      "beautiful young girl raising hands in classroom while sitting at a desk ------- beautiful young girl raising hand in classroom while sitting at a desk\n",
      "a man hanging out on the deck of his sailboat ------- a man hanging out on the deck of his sailboat\n",
      "a file photo of supporters during a match against football team. ------- a file photo of supporters during a match against football team.\n",
      "this cartoon shows a church in the sand today ------- this christian cartoon features a church facing today's challenges with it's head in the sand like an ostrich\n",
      "country artist performs on stage during festival in politician ------- country artist performs on stage during festival in politician\n",
      "flowers sprouting from the horizontal. ------- flowers sprouting from the horizontal runner.\n",
      "photo: view of the formal living room ------- photo: view of the formal living room\n",
      "chair- he was a designer who led the use of geometric patterns in the wood, ------- chair- he was a designer that led to the use of geometric patterns as you can see here in the wood and fabric.\n",
      "best party in the year! ------- best party of the year!\n",
      "politician meets with national security team ------- politician meets with his national security team\n",
      "colorful illustration of girl in the kitchen. ------- colorful illustration of girl in the kitchen.\n",
      "travel around the world: ------- travel around the world--\n",
      "the tops of the mountains are capped with snow. ------- the tops of the mountains were capped with snow.\n",
      "the layout of the tower mine. ------- the layout of the tower mine.\n",
      "hard to catch your prags in the prags. ------- hard to catch your stride in the pa.\n",
      "water fountain in the park ------- water fountain in the park\n",
      "what diamonds look like when cut to their standards. ------- what diamonds look like before they are cut.\n",
      "a bottle of white wine with its labels lying on the side with its reflection. ------- a bottle of white wine with blank labels lying on its side with its reflection below.\n",
      "person perching upside down on a blade of grass ------- person perching upside down on a blade of grass\n",
      "a return from your own talented musicians? a person with a sticker in a ------- reward your budding musicians with this you're person sticker. 125 per pack.\n",
      "i saw this person yesterday. ------- i saw this person today.\n",
      "officers from around the world ------- cops from around the world\n",
      "ball of gluten free cookie- a large brown tin in a large bowl. ------- ball of gluten- free coconut- lemon cookie dough in a large brown mixing bowl.\n",
      "red truck driving on the road at sunset ------- red truck driving on the road at sunset\n",
      "hot- air balloons flying in a field ------- hot- air balloons landing in a field\n",
      "incredible illustrations have become one of the rarest suites in the world. ------- incredible illustrations have caused it to become one of the rarest and most sought- after suites.\n",
      "take me to the ocean! ------- take me to the ocean.\n",
      "stack of pancakes with slashing down on the sides ------- stack of pancakes with syrup cascading down the sides\n",
      "the mountains are calling... but you must go to pack! ------- the mountains are calling, and i must go... things you may not think to pack trip!\n",
      "person as a 76 in the latest horror movie directed by person. ------- person as 79 in the upcoming horror movie, directed by person.\n",
      "like a lighthouse on the coast of the ocean-- things are a rope to ------- like a lighthouse on a coast... when things have gone haywire we need that light!\n",
      "dirt road in the mountains ------- dirt road in the mountains\n",
      "people living on their own beach ------- people living the dream on their own private beach\n",
      "remove the back of the phone with the fingers of the plastic. ------- remove the back cover of the phone with the plastic opening tool, or your fingers.\n",
      "old pinnacle on a headgeant. ------- old paneling as a headboard.\n",
      "my go- putting holiday sufflings piled high with fresh herbs and ------- my go- to holiday stuffing recipe loaded with fresh herbs, chopped apples, cranberries, and sausage!\n",
      "bats in the night sky ------- bats in the night sky\n",
      "booth during the antique show. ------- booth during the antique show!\n",
      "professional boxer attends the premiere of the new film ------- professional boxer attends the premiere of the new film\n",
      "you'll find it easier to survive a kitchen renovation by setting up an easy- to ------- you'll find it much easier to survive a kitchen renovation by setting up an easy- to- use temporary kitchen!\n",
      "cheerleader performs during a high school football game against person. ------- cheerleader performs during a high school football game against person.\n",
      "Validation EM Score: 0.305908203125\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    em_count = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for clip_inputs, t5_inputs in val_dataloader:\n",
    "        # Generate sequences\n",
    "        generated_ids = clip_model(clip_inputs, t5_inputs, train=False).detach().cpu().numpy()\n",
    "\n",
    "        # Decode token IDs to strings\n",
    "        generated_sentences = [tokenizer.decode(ids, skip_special_tokens=True) for ids in generated_ids]\n",
    "        target_sentences = t5_inputs['target']\n",
    "\n",
    "        # Check for exact match\n",
    "        em_count += sum(1 for gen, target in zip(generated_sentences, target_sentences) if gen == target)\n",
    "        total_samples += len(generated_sentences)\n",
    "        print(generated_sentences[0], '-------', target_sentences[0])\n",
    "\n",
    "    em_score = em_count / total_samples\n",
    "    print(f'Validation EM Score: {em_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m608.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
